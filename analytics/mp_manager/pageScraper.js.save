const fs = require('fs')
const parse_xlsx = require("./excelParser")
const xlsx = require("node-xlsx").default
const cookies = require('./cookies.json')
const scraperObject = {
    async scraper(browser, campaign_id){
		const url = `https://app.mpmgr.ru/organizations/${campaign_id}/campaigns/auto-campaigns`;
        const context = await browser.newContext();
//		context.setDefaultTimeout(60000*3)
		context.addCookies(cookies)
		const page = await context.newPage();
		console.log(`Navigating to ${url}...`);
		// Navigate to the selected page
		await page.goto(url);
		await page.waitForLoadState()
		// Wait for the required DOM to be rendered
		await page.waitForSelector('.MuiTypography-root.MuiTypography-inherit.MuiLink-root.MuiLink-underlineNone');
		await page.waitForTimeout(10000)
		// // Get the link to all the required books
        // const rating = await page.$eval('.rating-product__numb', el => el.textContent);
		let urls = await page.$$eval('.MuiTypography-root.MuiTypography-inherit.MuiLink-root.MuiLink-underlineNone', links => {
			// Extract the links from the data
			links = links.map(el => el.href)
			return links;
		});
		urls = urls.filter(link => link.includes('/campaign'))
//		console.log(urls);
		
		await page.close()
        await context.close()

		const good_campaign_ids = urls.filter(link => link.includes('/0/')).length == 0
		if (good_campaign_ids) {
			console.log(urls)

			const ids = []
			urls.forEach(link => ids.push(`[${link.split('/')[7]}]`))
			const path_to_file = `./files/${campaign_id}_presented.xlsx`
            fs.writeFileSync(path_to_file, xlsx.build([{ name: campaign_id, data: [ids] }]))
		}
		else { 
			return 
		}
	
		let pagePromise = (link) => new Promise(async(resolve, reject) => {
			let dataObj = {};
			
			const new_context = await browser.newContext();
//			new_context.setDefaultTimeout(60000*3)
			new_context.addCookies(cookies)
			const newPage = await new_context.newPage();

			await newPage.goto(link);
			await newPage.waitForLoadState()
			await newPage.waitForTimeout(10000)

			await newPage.waitForSelector('.MuiTypography-root.MuiTypography-h3.css-11j0d37').catch(error => {console.log('Invisible'); reject(dataObj)});


			//await newPage.$eval('.MuiBox-root.css-mxe89r > .MuiBox-root', async el => {
			//	if (getComputedStyle(el).color == 'rgba(255, 191, 76, 0.25)') {
			//		console.log('Paused campaign, leaving.')
			//		await new_context.close()
			//		reject(dataObj)
			//		await newPage.close()
			//		return
			//	}
			//})			


			dataObj['id'] = `[${link.split('/')[7]}]`
			dataObj['name'] = (await newPage.$eval('.MuiTypography-root.MuiTypography-h3.css-11j0d37', text => text.textContent));

			await newPage.waitForSelector('.MuiButtonBase-root.MuiAccordionSummary-root.css-1dkwt8e');
			await newPage.$eval('.MuiButtonBase-root.MuiAccordionSummary-root.css-1dkwt8e', el => el.click());
			await newPage.waitForTimeout(10000)
			
			//await newPage.getByText('Интервал').first().evaluate(el => el.click());
			
			//await newPage.locator('.rmdp-left')
			//await newPage.waitForTimeout(1000)
			//await newPage.locator('.sd').first().evaluate(el => el.click())
			//await newPage.waitForTimeout(1000)

			await newPage.getByText('Экспорт').first().waitFor()
			await newPage.waitForTimeout(5000)

			const downloadPromise = newPage.waitForEvent('download');
			await newPage.getByText('Экспорт').first().evaluate(el => el.click())
			const download = await downloadPromise;
			// Wait for the download process to complete
			// console.log(await download.path());
			// Save downloaded file somewhere

			const path_to_file = `./files/${campaign_id}/${dataObj['id']}.xlsx`
			await download.saveAs(path_to_file)

			// change sheet name to match current name in mp_manager
			const sheet = xlsx.parse(path_to_file)[0]
            fs.writeFileSync(path_to_file, xlsx.build([{ name: dataObj['name'], data: sheet['data'] }]))

			// await newPage.$eval('.MuiBox-root.css-1age63q > button', button => button.click());

			await newPage.close()
			await new_context.close()
			console.log(dataObj)
			resolve(dataObj)

		}).catch(error => {console.log('Passing error'); throw error})

		// let currentPageData = await pagePromise(urls[0]);
		// console.log(currentPageData)

		let scrapedData = [];
		// for(link in urls){
		// 	let currentPageData = await pagePromise(urls[link]);
		// 	scrapedData.push(currentPageData);
		// 	console.log(currentPageData);
		// }
		let all_page_promises = []
		for(link in urls){
			//all_page_promises.push(pagePromise(urls[link]))
			try {
				await pagePromise(urls[link]).then(pr => all_page_promises.push(pr)).catch(error => {console.log('Caught'); throw error})
			} catch (error) {
				//console.log(error)
				console.log('Retrying...')
				await pagePromise(urls[link]).then(pr => all_page_promises.push(pr)).catch(error => {console.log('Caught'); })
			}
			//await page.waitForTimeout(20000)
			//pagePromise(link).then(pr => all_page_promises.push(pr)).catch(error => {
			//	console.log(error)
			//	pagePromise(link).then(pr => all_page_promises.push(pr))
			//})
		}
		await Promise.all(all_page_promises)
		for (pr in all_page_promises) {
			scrapedData.push(pr);
//			console.log(pr);
		}

		await parse_xlsx(campaign_id)
    }
}

module.exports = scraperObject;


